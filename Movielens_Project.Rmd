%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your "contribution" to a contributed volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[graybox]{svmult}

% choose options for [] as required from the list
% in the Reference Guide

\usepackage{type1cm}        % activate if the above 3 fonts are
                            % not available on your system
%
\usepackage{makeidx}         % allows index generation
\usepackage{graphicx}        % standard LaTeX graphics tool
                             % when including figure files
\usepackage{multicol}        % used for the two-column index
\usepackage[bottom]{footmisc}% places footnotes at page bottom


\usepackage{newtxtext}       % 
\usepackage{newtxmath}       % selects Times Roman as basic font

% see the list of further useful packages
% in the Reference Guide

\makeindex             % used for the subject index
                       % please use the style svind.ist with
                       % your makeindex program

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Additional Packages%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\graphicspath{{./graphics/}}
\usepackage[noabbrev]{cleveref}
\usepackage{tabularx}
\usepackage[backend=biber,bibstyle=apa,citestyle=apa,natbib=true,sortcites=true,sorting=ynt]{biblatex}
\renewcommand*{\bibfont}{\small}
\usepackage{placeins} % For FloatBarrier
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{layout}
\setlist[enumerate]{align=left}
\usepackage{footnote}
\makesavenoteenv{tabular}
\makesavenoteenv{table}
\addbibresource{newreference.bib}

\usepackage{array} % This is to create commands for fixed lenght column in table
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}} % Fixed and central align
\newcolumntype{R}[1]{>{\PreserveBackslash\raggedleft}p{#1}}% Fixed and right align
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}p{#1}}% Fixed and left align

\setlength{\textfloatsep}{1ex}
\setlength{\intextsep}{1ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
%\setlength{\bibhang}{2em}
%\layout
\title*{Robust efficiency analysis of public hospitals in Queensland, Australia}
% Use \titlerunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\author{Bao Hoang Nguyen and Valentin Zelenyuk \thanks{We thank the Editor and two anonymous referees for many fruitful comments that helped improving this paper substantially. We acknowledge the support from our institution. We also acknowledge the financial support from the Australian Research Council (from the ARC Future Fellowship grant FT170100401). We thank Dan O'Halloran for his fruitful comments. We also thank David Du, Hong Ngoc Nguyen, Zhichao Wang and Evelyn Smart for their feedback from proofreading. We acknowledge and thank Queensland Health for providing part of the data that we used in this study. These individuals and organizations are not responsible for the views expressed in this paper.  }}
% Use \authorrunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\institute{Bao Hoang Nguyen \at School of Economics, University of Queensland, Brisbane, Qld 4072, Australia, \email{bao.nguyen3@uq.net.au}
\and Valentin Zelenyuk \at School of Economics and Centre for Efficiency and Productivity Analysis, University of Queensland, Brisbane, Qld 4072, Australia, \email{v.zelenyuk@uq.edu.au}}
%
% Use the package "url.sty" to avoid
% problems with special characters
% used in your e-mail or web address
%
\maketitle

%\abstract*{Each chapter should be preceded by an abstract (no more than 200 words) that summarizes the content. The abstract will appear \textit{online} at \url{www.SpringerLink.com} and be available with unrestricted access. This allows unregistered users to read the abstract as a teaser for the complete chapter.
%Please use the 'starred' version of the \texttt{abstract} command for typesetting the text of the online abstracts (cf. source file of this chapter template \texttt{abstract}) and include them with the source files of your manuscript. Use the plain \texttt{abstract} command if the abstract is also to appear in the printed version of the book.}
\textit{We dedicate our modest contribution to Professor Christine Thomas-Agnan--a great Scholar who together with various colleagues have originated, developed and inspired many interesting directions in research, among which is the concept of partial $\alpha$-frontier modelling that we use in this work.}
\newline

\abstract{In this study, we utilize various approaches for efficiency analysis to explore the state of efficiency of public hospitals in Queensland, Australia in the year 2016/17. Besides the traditional nonparametric approaches like DEA and FDH, we also use a more recent and very promising robust approach--order-$\alpha$ quantile frontier estimators \citep*{Aragon_etal_2005}. Upon obtaining the individual estimates from various approaches, we also analyse performance on a more aggregate level -- the level of Local Hospital Networks by using an aggregate efficiency measure constructed from the estimated individual efficiency scores. Our analysis suggests that the relatively low efficiency of some Local Hospital Networks in Queensland can be partially explained by the fact that the majority of their hospitals are small and located in remote areas.}

%\textbf{Keywords}: Hospital efficiency, Aggregate efficiency, DEA, FDH, Alpha frontier.
%
%\textbf{JEL Codes}: C24, C61, I11, I18. 
%\newpage
\section{Introduction}\label{sec:introduction}
In Australia, the provision of free public hospital services is the responsibility of the state and territory governments. The management of public hospitals in states and territories is usually geographically based. Since the National Health Reform Agreement in 2012 \citep*{NHRA_2011}, the governance of public hospitals in Australia has become more decentralised with the establishment of Local Hospital Networks. The Local Hospital Network is an independent statutory body established by each Australian state/territory government. Local Hospital Networks directly operate a group of public hospitals and are directly responsible for their performance. 

In Queensland, Local Hospital Networks are known as Hospital and Health Services (HHSs). There are 16 HHSs in the state, of these 15 HHSs are geographically based, the remaining one is a specialist statewide HHS dedicated to caring for children and young people. Each HHS is independently and locally controlled by a Hospital and Health Board and operated by a Health Service Chief Executive. HHSs relate to the Queensland Department of Health (Queensland Health) through a service agreement. Queensland Health acts as a system manager who has responsibility for purchasing healthcare services to cover the healthcare needs of citizens as well as monitoring the performance of HHSs. Meanwhile, each HHS acts as a provider whose function is to deliver healthcare services to its local community.

Although state and territory governments are responsible for delivering public hospital services, funding for public hospitals is provided by both federal and state/territory governments based on taxes collected from all states/territories across Australia. In the year 2016/17, 50\% of expenditure on public hospital services in Queensland came from the state government, while 40\% of the expenditure was provided by the Australian government \citep*{AIHW_2018b}. % Calculated based on Table B.9 in this report.
Public hospitals are funded either via Activity Based Funding or a Block Funding model. In Queensland, 36 hospitals (predominantly large and urban hospitals) are funded by Activity Based Funding.\footnote{Under Activity Based Funding, hospitals are reimbursed based on the number and the complexity of patient care episodes they provide. Hospitals receive a fixed rate for each episode, and the value of the fixed rate is determined by the DRG to which the episode belongs.} Meanwhile, 87 hospitals (mainly small and rural hospitals) are funded by Block Funding.

Public hospitals in Queensland are widely dispersed geographically with a relatively high proportion in regional and remote areas, which in part reflects the share of the state's population living outside the major cities and the obligation of the state government to provide equitable access to public hospital services for all residents. Public hospitals in the state are also diverse in terms of size: 91 out of 123 hospitals have 50 beds or fewer, yet 19 out of 123 hospitals have more than 200 beds and account for 75\% of Queensland's total hospital beds \citep*{AIHW2019}.

As public hospitals are the key institution in the acute healthcare sector where the majority of healthcare expenditure occurs, improving hospital efficiency has been viewed as a fundamentally important means to contain healthcare costs in Australia.
\footnote{In the fiscal year 2016/17, Australia spent \$181 billion on healthcare (more than \$7,400 per person and 10\% of its GDP), about a 57\% increase since 2006/07 (after adjusting for inflation). This turns out to be an average annual growth rate of 4.67\% over the decade: around 2\% higher than average growth of GDP \citep*{AIHW_2018b}.} 
In the study published in 2010, the \citet**{PC_2010} pointed out that the average inefficiency level of Australian hospitals is around 10\% and they would decrease operating expenditures by about 7\% if the inefficiency was eliminated. Given that the efficiency of public hospitals is an important issue of public concern and has now become the main responsibility of HHSs, it is important to analyse hospital performance, not only at the individual level but also at the HHS level. These analyses will provide useful information about the relative performance of HHSs and possibly identify sources of efficiency differentials, which are imperatively needed for any plan to promote hospital efficiency. 

This study will provide such an analysis by exploring the state of efficiency of public hospitals at the level of HHSs in Queensland, Australia in the year 2016/17. To analyse performance on the aggregate level, we utilize an aggregate efficiency measure constructed from individual efficiency scores estimated using various approaches. Besides the traditional nonparametric approaches like DEA and FDH, we also use a more recent and very promising robust approach--order-$\alpha$ quantile frontier estimators \citep*{Aragon_etal_2005}. The order-$\alpha$ quantile frontier estimators appear to be more appealing than the conventional nonparametric approaches because they are more robust with respect to extreme values and/or outliers in a finite sample and do not suffer from the well-known curse of dimensionality \citep*{Simar&Wilson_2013}.\footnote{Although the order-$\alpha$ quantile frontier estimators can provide new insights from the data compared to the traditional nonparametric estimators, the traditional approach, especially the CRS-DEA, still has its merits and value in itself (see more discussion in \Cref{sec:result}).} 

Based on  the robust estimates of aggregate efficiency, we use k-mean clustering technique (an unsupervised machine learning algorithm) to classify HHSs in Queensland into three groups, namely relatively low, medium, and high efficiency. Moreover, our analysis also suggests that the relatively low efficiency of some HHSs in Queensland can be partially explained by the fact that the majority of their hospitals are small and located in remote areas. 

Our paper is organized as follows. \Cref{sec:methodology} presents theoretical frameworks for efficiency measures and their nonparametric estimators. \Cref{sec:data} provides a description of the data sources and variables used in this study. \Cref{sec:result} discusses the results, and \Cref{sec:conclusion} provides concluding remarks. 
\section{Methodology}\label{sec:methodology}
\subsection{Theoretical concepts}
Let us consider a production process in which a production unit uses a set of $p$ inputs, denoted as $x=(x_{1},...,x_{p})^{'}\in\Re_{+}^{p}$, to produce a univariate output, denoted as $y \in \Re_{+}$.\footnote{For the cases of multiple-output, one can either follow the multivariate conditional quantile approach proposed by \citet*{Daouia&Simar_2007} or utilize aggregation techniques to aggregate outputs. In this study, we adopt \citeauthor{Daraio&Simar_2007}'s \citeyearpar{Daraio&Simar_2007} approach (the approach based on Principal Component Analysis) to aggregate hospital outputs into a single output measure. An alternative approach would be to use a price-based aggregation approach \citep{Zelenyuk_2020}.} According to the production theory \citep*{Shephard_1953,Shephard_1970}, the production technology can be mathematically characterized by a technology set defined as
\begin{equation}
\Psi =\left\{ (x,y)\in\Re_{+}^{p}\times\Re_{+}:x \text{ can produce } y\right\}. 
\end{equation}
Some regularity conditions are usually assumed for the technology set, among those the three most common assumptions are as follows \footnote{Other standard regularity conditions are "No Free Lunch" and "Producing Nothing is Possible" \citep*[see more details in][]{Sickles&Zelenuyk_2019}}
\begin{enumerate}
\item[A1.] $\Psi$ is closed.
\item[A2.] The output sets (defined in \eqref{eq:outputset} below) are bounded, $\forall x \in \Re_{+}^{p}$.
\item[A3.] All inputs and outputs are strongly disposable, i.e, $\left(x_0,y_0\right) \in \Psi \Rightarrow \left(x,y\right) \in \Psi, \forall x \geqq x_0, y \leqq y_0 $.
\end{enumerate}
The production technology can also be described mathematically in terms of its sections: input requirement set and output attainable set. In this paper, we measure efficiency in output direction, thus our discussion here focuses on the output attainable set.\footnote{Being similar to recent studies in the literature \citep*[e.g.,][]{Clement_etal_2008,Hu_etal_2012,Besstremyannaya_2013,Chowdhury&Zelenyuk_2016}, we measure efficiency in output direction because the level of inputs used in public hospitals is usually fixed and influenced by external factors (the budget of hospitals are usually planned in advance with relatively fixed (typically 12+ months) labour contracts and huge investment in fixed inputs). Moreover, an output-oriented model is consistent with the aim of Queensland Health, which is to maximize healthcare services delivered to local community from given resources \citep*[see][]{QH_2016}} It is defined as
\begin{equation} \label{eq:outputset}
P\left(x\right)=\left\{ y \in \Re_+:\left(x,y\right) \in \Psi \right\}, x \in \Re_{+}^{p}. 
\end{equation}
When efficiency is a concern, the boundary of the technology set is of interest. For the case of univariate output, the upper bound of the output attainable set (the production frontier) is also referred to as production function and defined as
\begin{equation} \label{eq:pf}
\partial P\left(x\right)= \max_{y}\left\{y \ \middle| \ y \in P\left(x\right)\right\}.
\end{equation}
The Farrell-type output oriented technical efficiency for the production unit is then defined as a radial distance from a point in output space representing the production unit toward the boundary and is defined mathematically as
\begin{equation} \label{eq:eff}
\lambda\left(x,y\right) = \sup_{\lambda}\left\{\lambda>0\ \middle| \ \lambda y \in P\left(x\right) \right\}=\sup_{\lambda}\left\{\lambda>0\ \middle| \ \left(x,\lambda y \right) \in \Psi \right\}.
\end{equation}
One might find it more convenient to look at the reciprocal of the output oriented efficiency (also known as the Shephard distance function) since it gives an efficiency measure between 0 and 1, where 1 stands for 100\% efficiency.

Now let us look at a more aggregate level, consider an industry of $n$ production units, $\mathcal{X}_n=\left\{\left(X_i,Y_i\right)\ \middle| \ i = 1,\dots, n \right\}$, which can be partitioned into $L$ groups (according some external economic criteria) with the input-output allocation of each group, say group $\ell$, denoted as $\mathcal{X}^\ell=\left\lbrace\left(X^\ell_i,Y^\ell_i\right)~\middle|~i=1,\dots,n_\ell\right\rbrace$, $\ell \in \left\lbrace 1,\cdots, L\right\rbrace$. One can measure the efficiency of each group $\ell$ in the industry by using the aggregate efficiency measure proposed by \citet**{Fare&Zelenyuk_2003}, extended by \citet*{Simar&Zelenyuk_2007} and further elaborated on in \citet*{Simar&Zelenyuk_2018}. The main advantage of this measure is that it uses meaningful weights derived from the economic optimization principle to aggregate individual efficiency scores in order to construct a group measure \citep*[see detail in][]{Fare&Zelenyuk_2003}. In the case of univariate output, the aggregate efficiency for group $\ell$ is the weighted average of individual efficiency scores, where weights are output shares of  individual production units in the group and is defined as

\begin{equation}
\overline{TE}^\ell= \sum_{i=1}^{n_\ell} \lambda\left(X^\ell_i,Y^\ell_i\right)\times S^\ell_i, \quad S^\ell_i=\dfrac{Y^\ell_i}{\sum_{i=1}^{n_\ell} Y^\ell_i}. \label{eq:TE}
\end{equation}

\subsection{Nonparametric estimators}\label{sec:estimators}
\subsubsection{DEA and FDH}
In practice, $\Psi$ is unknown and thus needs to be estimated from a sample of production units, say $\mathcal{X}_n$. There have been two widely-used approaches to estimate the production frontiers in the literature, usually referred to as the `deterministic frontier models' and the `stochastic frontier models'. The deterministic frontier models assume all observed production units belong to the technology set with probability one, whereas the stochastic frontier models allow some observations to be outside of the technology set by including two-sided random noise. The traditional stochastic frontier approach (SFA) requires parametric restrictions on the shape of the production frontier and on the data generating process to estimate the frontier and to identify the inefficiency term from the random noise component.\footnote{The traditional stochastic frontier approach was proposed independently by \citet*{Aigner_etal_1977} and \citet*{Meeusen&vanDenBroeck_1977}.} Recently, semiparametric and nonparametric estimators have been developed for stochastic frontier models to mitigate the parameterization of the approach \citep*[see more details in][]{Parmeter&Zelenyuk_2019}. 

The deterministic frontier models appear to be more appealing because they are usually handled via nonparametric estimators and rely on less restrictive assumptions. The most flexible deterministic frontier model is the Free Disposal Hull (FDH) estimator introduced by \citet*{Deprins_etal_1984}, which requires only the strong disposability assumption on the technology set. If, in addition, one imposes the convexity assumption on the technology set, one can use the Data Envelopment Analysis (DEA) estimator, which was initiated by \citet*{Farrell_1957} and popularized by \citet*{Charnes_etal_1978}. For DEA models, one can further impose constant returns to scale (CRS) or variable returns to scale (VRS) on the technology set to obtain CRS-DEA or VRS-DEA estimators \citep*{Fare_etal_1983,Banker_etal_1984}. The three estimators can be formulated respectively as follows

\begin{small}
\begin{align}
&\widehat{\Psi}_{FDH}\equiv\left\lbrace (x,y):y\leq\sum_{i=1}^{n}\zeta_{i}Y_i,x\geq\sum_{i=1}^{n}\zeta_{i}X_{i},\sum_{i=1}^{n}\zeta_i= 1,\zeta_{i} \in \left\{0,1\right\},i=1,\ldots,n\right\rbrace,\\
&\widehat{\Psi}_{CRS-DEA}\equiv\left\lbrace (x,y):y\leq\sum_{i=1}^{n}\zeta_{i}Y_i,x\geq\sum_{i=1}^{n}\zeta_{i}X_{i},\zeta_{i}\geq0,i=1,\ldots,n\right\rbrace,\\
&\widehat{\Psi}_{VRS-DEA}\equiv\left\lbrace (x,y):y\leq\sum_{i=1}^{n}\zeta_{i}Y_i,x\geq\sum_{i=1}^{n}\zeta_{i}X_{i},\sum_{i=1}^{n}\zeta_i= 1,\zeta_{i}\geq0,i=1,\ldots,n\right\rbrace.
\end{align}
\end{small}

The FDH/DEA estimators of technical efficiency are obtained by plugging $\widehat{\Psi}_{FDH}$ or $\widehat{\Psi}_{CRS-DEA}$ or $\widehat{\Psi}_{VRS-DEA}$ in \eqref{eq:eff}. The asymptotic properties of FDH/DEA estimators have been well-established in the literature \citep*[e.g., see][]{Kneip_etal_1998,Kneip_etal_2008, Park_etal_2010, Park_etal_2000}. In summary, under appropriate assumptions, the estimators are consistent (converging to the true values when sample sizes go to infinity) and have limiting distributions. Convergence rates depend on the type of estimators and the dimension of input-output space (the number of inputs, $p$, plus the number of outputs, $q$). To be more specific, the convergence rates for FDH, CRS-DEA, VRS-DEA estimators are   $n^\kappa$ , where $\kappa$ $=$ $1/(p+q)$, $2/(p+q)$, or $2/(p+q +1)$, respectively \citep*[e.g., see more discussion in ][]{Simar&Wilson_2015,Sickles&Zelenuyk_2019}.

The envelopment estimators of aggregate efficiency of group $\ell$ then can be obtained by plugging the envelopment estimators of individual efficiency into equation \eqref{eq:TE} 
\begin{equation}
\widehat{\overline{TE}}^\ell= \sum_{i=1}^{n_\ell} \hat{\lambda}\left(X^\ell_i,Y^\ell_i|\mathcal{X}_n\right)\times S^\ell_i, \quad S^\ell_i=\dfrac{Y^\ell_i}{\sum_{i=1}^{n_\ell} Y^\ell_i}.
\end{equation}

\subsubsection{Partial frontiers}
The deterministic frontier models, however, are particularly sensitive to extreme values and/or outliers because by construction, they fully envelop all observed data. Various techniques have been proposed to deal with the disadvantage. One approach is to identify and possibly delete any outliers in the data, but the approach, to some extent, depends on how the researcher defines an ‘outlier’ \citep*{Simar&Wilson_2015}. As an alternative, one can also use the stochastic versions of DEA and FDH, where data is prewhitened from the noise and outliers using nonparametric SFA in the first stage and DEA/FDH is applied to estimate efficiency in the second stage \citep*[e.g., see][]{Simar_2007,Simar&Zelenyuk_2011}. 

Another approach is to use robust partial frontier estimators. There are mainly two types of partial frontiers, which are: (i) order-$m$ frontiers introduced by \citet*{Cazals_etal_2002} and (ii) order-$\alpha$ quantile frontiers introduced by \citet*{Aragon_etal_2005} and extended by \citet*{Daouia&Simar_2007}. The idea of partial frontier estimators is to estimate something "close" to but not the boundary of the technology set \citep*{Simar&Wilson_2013}. For example, in output orientation, order-$m$ frontiers are defined as the expected maximum obtainable outputs among $m$ production units drawn randomly from the population of those using at most a given level of inputs. Meanwhile, order-$\alpha$ quantile frontiers represent the expected maximum output levels that are exceeded by $100\left(1-\alpha\right)\%$ of production units using less than or equal to a given level of inputs.

The nonparametric estimators of these frontiers turn out to be more appealing than the conventional deterministic frontier models because they do not suffer from the well-known curse of dimensionality and achieve the standard parametric root-$n$ ($\sqrt{n}$) rate of convergence (for a fixed value of order $\alpha$) \citep*{Cazals_etal_2002,Aragon_etal_2005,Daouia&Simar_2007}. Moreover, both the estimators are also consistent estimators of the full frontier and share asymptotic properties with FDH estimators but are more robust with respect to extreme values and/or outliers in finite sample than the conventional FDH or DEA estimators \citep*{Simar&Wilson_2013}. 

Among the two above-mentioned partial frontier approaches, the order-$\alpha$ quantile frontier estimators are argued to have better robustness properties than the order-$m$ frontier estimators. For example, \citet*{Aragon_etal_2005} compared the two estimators using various simulated data sets, and reached the same conclusion with all the data sets that the order-$m$ frontier estimators are less resistant to outliers than the order-$\alpha$ quantile frontier estimators. \citet*{Daouia&Simar_2007} examined the robustness properties of the two estimators from the theoretical points of view using the concept of influence function, and came up with the same conclusion. Thus, we will use the order-$\alpha$ quantile frontier estimators in our analysis and focus our discussion on these estimators.     

Let us define the technology set $\Psi$ as the support of the joint distribution of a random variable $\left(X,Y\right)$, which generates the random sample $\mathcal{X}_n$. Here, we  focus on the interior of the set, $\Psi^*=\left\{\left(x,y\right) \in \Psi \middle | F_X\left(x\right)>0 \right\}$, where $F_X\left(\cdot\right)$ represents the marginal distribution of $X$. As in \citet*{Cazals_etal_2002}, the production function defined in \eqref{eq:pf} can be rewritten in a probabilistic representation as
\begin{equation} 
\partial P\left(x\right)= \sup_{y}\left\{y \ \middle|\  F_{Y|X}\left(y|x\right)< 1\right\},
\end{equation}
where $F_{Y|X}\left(y|x\right)$ is the conditional distribution of $Y$ given $X \leq x$, i.e.,
\begin{equation}
F_{Y|X}\left(y|x\right)=\dfrac{F_{XY}\left(x,y\right)}{ F_X\left(x\right)},
\end{equation}
where $F_{XY}\left(x,y\right)=\text{Prob}\left(X\leq x, Y \leq y\right)$ is the joint distribution of $\left(X,Y\right)$.

Equivalently, $\partial P\left(x\right)$ can be formulated as the order one quantile of the distribution of $Y$ given $X \leq x$ as
\begin{equation}
q_1\left(x\right)=\inf_{y}\left\{y \geq 0 \ \middle| \ F_{Y|X}\left(y|x\right)=1\right\}.
\end{equation}
One can interpret $q_1\left(x\right)$ as the minimum output level not exceeded by any production unit using at most $x$ inputs. Based on the formulation, \citet*{Aragon_etal_2005} introduced a concept of order-$\alpha$ quantile frontiers as the quantile functions of order $\alpha$, $\alpha \in \left[0,1\right]$, of the distribution of $Y$ given that $X$ is less than or equal to a given level of inputs and defined as
\begin{equation}\label{eq:alphafro}
q_\alpha\left(x\right)= \inf_y\left\{y \geq 0 \ \middle| \ F_{Y|X}\left(y|x\right)\geq \alpha \right\}.
\end{equation}
The order-$\alpha$ quantile frontier, $q_\alpha\left(x\right)$, represents the output threshold exceeded by \\\ $100\left(1-\alpha\right)\%$ of production units using at most $x$ inputs. The efficiency measure with respect to the frontier is referred to as the order-$\alpha$ quantile efficiency and defined as
\begin{equation}\label{eq:alphaef}
\lambda_\alpha\left(x,y\right)= \inf_\lambda\left\{\lambda\  \middle|\ F_{Y|X}\left(\lambda y|x\right)\geq \alpha \right\}.
\end{equation}
The order-$\alpha$ quantile efficiency represents the radial distance from a point in output space representing the production unit toward the order-$\alpha$ quantile frontier. The measure $\lambda_\alpha\left(x,y\right)$ can have values between 0 and $+\infty$, where $\lambda_\alpha\left(x,y\right)<1$ indicates that the production unit with input-output allocation $\left(x,y\right)$ is above the order-$\alpha$ quantile frontier (i.e., super-efficient production unit).
  
To estimate order-$\alpha$ quantile frontiers and  order-$\alpha$ quantile efficiency, we can apply the plug-in principle by replacing $F_{Y|X}\left(\cdot|\cdot\right)$ in \eqref{eq:alphafro} and  \eqref{eq:alphaef}, respectively, by its empirical analogue
\begin{equation}\
\widehat{q}_{\alpha,n}\left(x\right)= \inf_y\left\{y \geq 0 \ \middle| \ \widehat{F}_{Y|X}\left(y|x\right)\geq \alpha \right\}
\end{equation}
and
\begin{equation}
\widehat{\lambda}_{\alpha,n}\left(x,y\right)= \inf_\lambda\left\{\lambda\  \middle|\ \widehat{F}_{Y|X}\left(\lambda y|x\right)\geq \alpha \right\}.
\end{equation}

As an extension of Theorem 4.1 in \citet*{Aragon_etal_2005}, \citet*{Daouia&Simar_2007} show that under appropriate assumptions, order-$\alpha$ quantile efficiency estimators have asymptotic normality with the standard parametric root-$n$ ($\sqrt{n}$) rate of convergence for a fixed value of order $\alpha$.
Moreover, the order-$\alpha$ quantile efficiency estimators converge to the FDH estimator as $\alpha \rightarrow 1$ 
\begin{equation}
\lim_{\alpha \rightarrow 1} \widehat{\lambda}_{\alpha,n}\left(x,y\right) = \widehat{\lambda}_{FDH}\left(x,y\right).
\end{equation}
More details on this interesting method can be found in \citet*{Aragon_etal_2005} and \citet*{Daouia&Simar_2007}, while in the next section we will apply it to analyse the efficiency of public hospitals in Queensland, Australia.

Before going to discuss the empirical results, it is worth noting here that individual efficiency of each hospital in this study is estimated using the entire industry sample (a sample of size $n$). It is also important to emphasize that while we recognize that each hospital may use different technologies (and potentially much more complex than any model can handle), the goal of this study is to measure the relative efficiency with respect to the frontier of the unconditional technology set, where the so-called “separability assumption” \citep{Simar&Wilson_2007, Simar&Wilson_2011} is satisfied by definition.  In a sense, it is similar to a grand competition, like Olympics or country-wide student evaluation, where everyone is measured with respect to the same criteria, regardless of their backgrounds.

It is very well possible that further stratification of the sample is needed to account for various conditions that each of the hospitals may face and potentially may prevent them from reaching the frontier of the unconditional technology set. In such cases, an alternative (as well as complementary) strategy would be to take the so-called conditional frontier approach, where the frontier may vary across different groups or even depend on the values of various continuous variables (and thus allow for uncountably infinite possibilities of different frontiers).\footnote{E.g., one could use  \citeauthor{Badin_etal_2012}'s \citeyearpar{Badin_etal_2012} approach or, alternatively, a non-parametric stochastic approach \citep[e.g., see][and references therein]{Simar_etal_2017, Parmeter&Zelenyuk_2019}.}  

To be more precise, the conditional technology can be defined \citep[following][]{Simar&Wilson_2007, Simar&Wilson_2011} as 
$$\Psi^z=\left\{\left(X,Y\right)\middle| X \ \text{can produce} \  Y \ \text{when} \ Z=z\right\},$$
where $Z$ is a vector of conditioning variables (potentially very large one, and in reality possibly endogenous to the production unit), and $z$ is a particular value it may take out of the all the possibilities, denoted by the set $\mathcal{Z}$.  Meanwhile, the unconditional technology (which we focus on here) is then defined as 
$$\Psi=\bigcup_{z\in \mathcal{Z}}\Psi^z,$$
which does not depend on $Z$. 

Recently, rigorous statistical tests have been developed to verify which of the pre-selected models fit a given data ‘tighter’ according to a selected statistic